version: '3.8'

services:
  web:
    build: .
    volumes:
      - .:/app
    ports:
      - "8000:8000"
    environment:
      - DEBUG=False
      - OLLAMA_API_URL=http://host.docker.internal:11434
    depends_on:
      - ollama-service

  ollama-service:
    image: ollama/ollama:latest
    ports:
      - "11434:11434"
    volumes:
      - ollama_data:/root/.ollama
    # GPU support would need 'deploy: resources: reservations: devices: - capabilities: [gpu]'
    # For A100 setup, ensure nvidia-container-toolkit is installed on host.
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: 1
              capabilities: [ gpu ]

volumes:
  ollama_data:
